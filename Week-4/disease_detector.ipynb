{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(image_dir, csv_path, image_dimensions = [256, 256]):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    labels = df[['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']].values\n",
    "    image_names = df['image']\n",
    "    image_paths = [os.path.join(image_dir, f\"{name}.jpg\") for name in image_names]\n",
    "\n",
    "    def load_image(file_path, label):\n",
    "        img = tf.io.read_file(file_path)\n",
    "        img = tf.image.resize(tf.image.decode_jpeg(img, channels = 3), image_dimensions)\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        img = tf.add(img, 0.05)\n",
    "        img = tf.clip_by_value(img, 0, 1)\n",
    "        return img, label\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(load_image, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "    return dataset, len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RobustAsymmetricLoss(y_true, y_pred, gamma_pos, gamma_neg, lambda_, alpha, beta, tau, M, N):\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "    num_classes = tf.shape(y_true)[-1]\n",
    "    batch_size = tf.shape(y_true)[0]\n",
    "    pos_loss = tf.zeros((batch_size, num_classes), dtype = tf.float32)\n",
    "    neg_loss = tf.zeros((batch_size, num_classes), dtype = tf.float32)\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        temp_1 = tf.zeros((batch_size, ), dtype = tf.float32)\n",
    "        temp_2 = tf.zeros((batch_size, ), dtype = tf.float32)\n",
    "        for m in range(1, M + 1):\n",
    "            temp_1 += alpha[m - 1] * tf.pow(1.0 - y_pred[:, c], m + gamma_pos)\n",
    "        for n in range(1, N + 1):\n",
    "            temp_2 += beta[n - 1] * tf.pow(tf.maximum(y_pred[:, c] - tau, 0), n + gamma_neg)\n",
    "        indices = tf.stack([tf.range(batch_size), tf.fill([batch_size], c)], axis=1)\n",
    "        pos_loss = tf.tensor_scatter_nd_update(pos_loss, indices, tf.cast(y_true[:, c], dtype=tf.float32) * temp_1)\n",
    "        neg_loss = tf.tensor_scatter_nd_update(neg_loss, indices, (lambda_[c] - y_pred[:, c]) * (1.0 - tf.cast(y_true[:, c], dtype=tf.float32)) * temp_2)\n",
    "\n",
    "    loss = tf.reduce_sum(pos_loss, axis = 1) + tf.reduce_sum(neg_loss, axis = 1)\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizedMulticlassAccuracy(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='normalized_multiclass_accuracy', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.num_classes = 7\n",
    "        self.total = self.add_weight(name='total', initializer='zeros')\n",
    "        self.count = self.add_weight(name='count', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.argmax(y_true, axis=-1)\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "        values = tf.cast(tf.equal(y_true, y_pred), tf.float32)\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, self.dtype)\n",
    "            values = tf.multiply(values, sample_weight)\n",
    "        self.total.assign_add(tf.reduce_sum(values))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return (self.total / self.count) * self.num_classes\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.total.assign(0.)\n",
    "        self.count.assign(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_size = create_dataset(\n",
    "    image_dir = 'train_images',\n",
    "    csv_path = 'Training_GroundTruth.csv',\n",
    "    image_dimensions = [256, 256],\n",
    ")\n",
    "def augment_image(img, label):\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "    img = tf.image.random_brightness(img, max_delta=0.2)\n",
    "    img = tf.image.random_contrast(img, lower=0.8, upper=1.2)\n",
    "    img = tf.image.random_saturation(img, lower=0.8, upper=1.2)\n",
    "    img = tf.image.random_hue(img, max_delta=0.2)\n",
    "    img = tf.image.random_crop(img, size=[224, 224, 3])\n",
    "    img = tf.image.resize(img, [256, 256])\n",
    "    return img, label\n",
    "train_dataset = train_dataset.map(augment_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.cache().shuffle(buffer_size = train_size).batch(32).prefetch(buffer_size = tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "num_classes = 7\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    model = Sequential([\n",
    "        Input(shape = (256, 256, 3)),\n",
    "        Conv2D(32, (3, 3), activation = 'relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(64, (3, 3), activation = 'relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(128, (3, 3), activation = 'relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(256, (3, 3), activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(512, (3, 3), activation = 'relu'),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax'),\n",
    "    ])\n",
    "    M, N = 3, 3\n",
    "    alpha = tf.constant([1.0 for _ in range(M)], dtype=tf.float32)\n",
    "    beta = tf.constant([1.0 for _ in range(N)], dtype=tf.float32)\n",
    "    gamma_pos = tf.constant(2.0, dtype=tf.float32)\n",
    "    gamma_neg = tf.constant(1.0, dtype=tf.float32)\n",
    "    lambda_ = tf.constant([5.32, 1.00, 9.77, 21.14, 4.19, 20.66, 25.97], dtype=tf.float32)\n",
    "    tau = tf.constant(0.5, dtype=tf.float32)\n",
    "    normalized_accuracy = NormalizedMulticlassAccuracy()\n",
    "    model.compile(\n",
    "        loss = lambda y_true, y_pred: RobustAsymmetricLoss(y_true, y_pred, gamma_pos, gamma_neg, lambda_, alpha, beta, tau, M, N),\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate = 0.003),\n",
    "        metrics = [NormalizedMulticlassAccuracy()],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 114s 256ms/step - loss: 0.9937 - normalized_multiclass_accuracy: 4.6711\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 74s 238ms/step - loss: 0.9915 - normalized_multiclass_accuracy: 4.6865\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 74s 237ms/step - loss: 0.9915 - normalized_multiclass_accuracy: 4.6865\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 74s 237ms/step - loss: 0.9915 - normalized_multiclass_accuracy: 4.6865\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 75s 239ms/step - loss: 0.9915 - normalized_multiclass_accuracy: 4.6865\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 75s 241ms/step - loss: 0.9915 - normalized_multiclass_accuracy: 4.6865\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 74s 238ms/step - loss: 0.9915 - normalized_multiclass_accuracy: 4.6865\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 74s 235ms/step - loss: 0.9915 - normalized_multiclass_accuracy: 4.6865\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 73s 235ms/step - loss: 0.9915 - normalized_multiclass_accuracy: 4.6865\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 74s 235ms/step - loss: 0.9915 - normalized_multiclass_accuracy: 4.6865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1581cde40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 4s 54ms/step\n",
      "Normalized Multi-class Accuracy: 0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "test_dataset, test_size = create_dataset('test_images', 'Test_GroundTruth.csv', [256, 256])\n",
    "test_dataset = test_dataset.cache().batch(32).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "y_pred = model.predict(test_dataset)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "y_true = np.argmax(y_true, axis=1) if y_true.ndim > 1 else y_true\n",
    "\n",
    "def normalized_multi_class_accuracy(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.arange(num_classes))\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    return np.mean(np.diag(cm_normalized))\n",
    "\n",
    "normalized_accuracy = normalized_multi_class_accuracy(y_true, y_pred_classes)\n",
    "\n",
    "print(f\"Normalized Multi-class Accuracy: {normalized_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnassignment_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
